"""
API data models for AIStudioProxy.

This module defines Pydantic models for OpenAI-compatible API requests and responses.
"""

from typing import Any, Dict, List, Optional, Union
from enum import Enum

from pydantic import BaseModel, Field, field_validator


class MessageRole(str, Enum):
    """Message role enumeration."""
    SYSTEM = "system"
    USER = "user"
    ASSISTANT = "assistant"


class Message(BaseModel):
    """Chat message model."""
    role: MessageRole = Field(..., description="The role of the message author")
    content: str = Field(..., description="The content of the message")
    name: Optional[str] = Field(None, description="The name of the author")
    
    @field_validator('content')
    def validate_content(cls, v):
        if not v or not v.strip():
            raise ValueError("Message content cannot be empty")
        if len(v) > 100000:  # 100KB limit
            raise ValueError("Message content too long")
        return v.strip()


class ChatCompletionRequest(BaseModel):
    """Chat completion request model."""
    model: str = Field(..., description="ID of the model to use")
    messages: List[Message] = Field(..., min_items=1, max_items=100, description="List of messages")
    temperature: Optional[float] = Field(None, ge=0.0, le=2.0, description="Sampling temperature")
    top_p: Optional[float] = Field(None, ge=0.0, le=1.0, description="Nucleus sampling parameter")
    max_tokens: Optional[int] = Field(None, ge=1, le=4096, description="Maximum tokens to generate")
    stream: bool = Field(False, description="Whether to stream back partial progress")
    stop: Optional[Union[str, List[str]]] = Field(None, description="Stop sequences")
    presence_penalty: Optional[float] = Field(None, ge=-2.0, le=2.0, description="Presence penalty")
    frequency_penalty: Optional[float] = Field(None, ge=-2.0, le=2.0, description="Frequency penalty")
    user: Optional[str] = Field(None, description="Unique identifier for the end-user")
    
    @field_validator('messages')
    def validate_messages(cls, v):
        if not v:
            raise ValueError("Messages list cannot be empty")
        
        # Check total content length
        total_length = sum(len(msg.content) for msg in v)
        if total_length > 100000:  # 100KB total limit
            raise ValueError("Total message content too long")
        
        return v
    
    @field_validator('model')
    def validate_model(cls, v):
        # This will be validated against supported models in the handler
        if not v or not v.strip():
            raise ValueError("Model cannot be empty")
        return v.strip()


class Usage(BaseModel):
    """Token usage information."""
    prompt_tokens: int = Field(..., description="Number of tokens in the prompt")
    completion_tokens: int = Field(..., description="Number of tokens in the completion")
    total_tokens: int = Field(..., description="Total number of tokens")


class ChatCompletionChoice(BaseModel):
    """Chat completion choice."""
    index: int = Field(..., description="The index of this choice")
    message: Message = Field(..., description="The message generated by the model")
    finish_reason: Optional[str] = Field(None, description="The reason the model stopped generating")


class ChatCompletionResponse(BaseModel):
    """Chat completion response model."""
    id: str = Field(..., description="Unique identifier for the completion")
    object: str = Field(default="chat.completion", description="Object type")
    created: int = Field(..., description="Unix timestamp of creation")
    model: str = Field(..., description="The model used for completion")
    choices: List[ChatCompletionChoice] = Field(..., description="List of completion choices")
    usage: Usage = Field(..., description="Token usage information")


class StreamChoice(BaseModel):
    """Streaming chat completion choice."""
    index: int = Field(..., description="The index of this choice")
    delta: Dict[str, Any] = Field(..., description="The delta message")
    finish_reason: Optional[str] = Field(None, description="The reason the model stopped generating")


class ChatCompletionStreamResponse(BaseModel):
    """Streaming chat completion response model."""
    id: str = Field(..., description="Unique identifier for the completion")
    object: str = Field(default="chat.completion.chunk", description="Object type")
    created: int = Field(..., description="Unix timestamp of creation")
    model: str = Field(..., description="The model used for completion")
    choices: List[StreamChoice] = Field(..., description="List of completion choices")


class Model(BaseModel):
    """Model information."""
    id: str = Field(..., description="Model identifier")
    object: str = Field(default="model", description="Object type")
    created: int = Field(..., description="Unix timestamp of creation")
    owned_by: str = Field(default="google", description="Organization that owns the model")


class ModelListResponse(BaseModel):
    """Model list response."""
    object: str = Field(default="list", description="Object type")
    data: List[Model] = Field(..., description="List of available models")


class ErrorDetail(BaseModel):
    """Error detail information."""
    message: str = Field(..., description="Error message")
    type: str = Field(..., description="Error type")
    param: Optional[str] = Field(None, description="Parameter that caused the error")
    code: Optional[str] = Field(None, description="Error code")


class ErrorResponse(BaseModel):
    """Error response model."""
    error: ErrorDetail = Field(..., description="Error details")


class HealthResponse(BaseModel):
    """Health check response."""
    status: str = Field(..., description="Service status")
    timestamp: int = Field(..., description="Unix timestamp")
    version: str = Field(..., description="Service version")
    uptime: float = Field(..., description="Service uptime in seconds")
    browser_status: str = Field(..., description="Browser status")
    auth_status: str = Field(..., description="Authentication status")


class MetricsResponse(BaseModel):
    """Metrics response model."""
    requests_total: int = Field(..., description="Total number of requests")
    requests_success: int = Field(..., description="Number of successful requests")
    requests_error: int = Field(..., description="Number of failed requests")
    average_response_time: float = Field(..., description="Average response time in seconds")
    active_connections: int = Field(..., description="Number of active connections")
    browser_sessions: int = Field(..., description="Number of active browser sessions")
    uptime: float = Field(..., description="Service uptime in seconds")
